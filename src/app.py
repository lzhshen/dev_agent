import streamlit as st
from langchain_core.messages import AIMessage, HumanMessage
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate

from streamlit_float import *

from langchain.agents import create_tool_calling_agent
from langchain.agents import AgentExecutor
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain.agents import AgentType, initialize_agent, load_tools

user_story_template = """
You are a business analyst who is familiar with specification by example. Iâ€™m the domain expert.
// ä½ æ˜¯ä¸€ä¸ªä¸šåŠ¡åˆ†æå¸ˆï¼Œè€Œæˆ‘æ˜¯é¢†åŸŸä¸“å®¶ 

===CONTEXT
{context}
===END OF CONTEXT

===USER STORY
{story}
===END OF USER STORY 

Explain the user story as scenarios. Use the following format:
// ä½¿ç”¨ åœºæ™¯ è§£é‡Šç”¨æˆ·æ•…äº‹ï¼Œå¹¶éµå¾ªå¦‚ä¸‹æ ¼å¼ 

Thought: you should always think about what is still uncertain about the user story. Ignore technical concerns.
// æ€è€ƒï¼šä½ åº”è¯¥è€ƒè™‘ç”¨æˆ·æ•…äº‹ä¸­ä¸æ¸…æ™°çš„éƒ¨åˆ†ã€‚ä½†å¿½ç•¥æŠ€æœ¯ç»†èŠ‚
Question: the question to ask to clarify the user story
// é—®é¢˜ï¼šæå‡ºé—®é¢˜å¸®åŠ©ä½ æ¾„æ¸…è¿™ä¸ªç”¨æˆ·æ•…äº‹
Answer: the answer I responded to the question
// å›ç­”ï¼šæˆ‘ç»™å‡ºç­”æ¡ˆ
â€¦ (this Thought/Question/Answer repeat at least 3 times, at most 10 times)
//ï¼ˆThought/Question/Answer é‡å¤è‡³å°‘ 3 æ¬¡è€Œä¸å¤šäº 10 æ¬¡ï¼‰
Thought: I know enough to explain the user story
// æ€è€ƒï¼šæˆ‘å·²ç»å¯¹è¿™ä¸ªç”¨æˆ·æ•…äº‹äº†è§£äº†è¶³å¤Ÿå¤šçš„å†…å®¹
Scenarios: List all possible scenarios with concrete example in Given/When/Then style
// åœºæ™¯ï¼šåˆ—å‡ºæ‰€æœ‰åœºæ™¯ã€‚ä½¿ç”¨ Given/When/Then çš„æ ¼å¼è¡¨è¿°

{history}
{input}
è¯·ä½¿ç”¨ä¸­æ–‡
"""

# app config
st.set_page_config(page_title="Streaming bot", page_icon="ğŸ¤–", layout="wide")
st.title("Streaming bot")

float_init(theme=True, include_unstable_primary=False)

load_dotenv()
from langchain_community.tools import HumanInputRun

def get_response(user_query, chat_history, user_story, business_ctx):
  
    llm = ChatOpenAI(temperature=0.0, model="gpt-4-turbo-preview")
    tools = load_tools(["human"])

    agent_chain = initialize_agent(
        tools,
        llm,
        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
        verbose=True,
    )
    prompt = ChatPromptTemplate.from_template(user_story_template)
    prompt_value = prompt.invoke(
        {
            "history": chat_history,
            "input": user_query,
            "story": user_story,
            "context": business_ctx,
        }
    )
    return agent_chain.invoke(prompt_value)

left_column, right_column = st.columns(2)

# Initialize chat history
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
    border = False
else:
    border = True

# session state
if "chat_history" not in st.session_state:
    st.session_state.chat_history = [
        AIMessage(content="Hello, I am a bot. How can I help you?"),
    ]
    border = False
else:
    border = True

# with right_column:
user_story = st.text_area(
    "User Story",
    """ä½œä¸ºå­¦æ ¡çš„æ•™èŒå‘˜å·¥ï¼ˆAs a facultyï¼‰ï¼Œ
    æˆ‘å¸Œæœ›å­¦ç”Ÿå¯ä»¥æ ¹æ®å½•å–é€šçŸ¥å°†å­¦ç±æ³¨å†Œåˆ°æ•™å­¦è®¡åˆ’ä¸Šï¼ˆI want the student to be able to enroll in an academic program with given offerï¼‰ï¼Œ
    ä»è€Œæˆ‘å¯ä»¥è·Ÿè¸ªä»–ä»¬çš„è·å–å­¦ä½çš„è¿›åº¦ï¼ˆSo that I can track their progressï¼‰""",
    height= 300,
)

business_ctx = st.text_area(
    "Business Context",
    "æ•´ä¸ªå­¦ç±ç®¡ç†ç³»ç»Ÿæ˜¯ä¸€ä¸ª Web åº”ç”¨ï¼› å½“æ•™èŒå‘˜å·¥å‘æ”¾å½•å–é€šçŸ¥æ—¶ï¼Œä¼šåŒæ­¥å»ºç«‹å­¦ç”Ÿçš„è´¦å·ï¼›å­¦ç”Ÿå¯ä»¥æ ¹æ®èº«ä»½ä¿¡æ¯ï¼ŒæŸ¥è¯¢è‡ªå·±çš„è´¦å·ï¼›åœ¨æŠ¥é“æ³¨å†Œæ—¶ï¼Œå­¦ç”Ÿç™»å½•è´¦å·ï¼ŒæŒ‰ç…§å½•å–é€šçŸ¥ä¹¦å®Œæˆå­¦å¹´çš„æ³¨å†Œï¼›",
    height= 300,
)

# with left_column:    
with st.container(border=border, height=800):
    # conversation
    for message in st.session_state.chat_history:
        if isinstance(message, AIMessage):
            with st.chat_message("AI"):
                st.write(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("Human"):
                st.write(message.content)

    # user input
    user_query = ''
    with st.container():
        user_query = st.chat_input("What is up?")
        button_b_pos = "0rem"
        button_css = float_css_helper(width="2.2rem", bottom=button_b_pos, transition=0)
        float_parent(css=button_css)

    if user_query is not None and user_query != "":
        st.session_state.chat_history.append(HumanMessage(content=user_query))

        with st.chat_message("Human"):
            st.markdown(user_query)

        with st.chat_message("AI"):
            response = st.write_stream(get_response(user_query, st.session_state.chat_history, user_story, business_ctx))

        st.session_state.chat_history.append(AIMessage(content=response))


